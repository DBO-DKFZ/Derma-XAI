{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7329e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb802cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metadata(data_path, participant_id_column, dropna_subset_col):\n",
    "    \"\"\"\n",
    "    Read each group's response file and loop through each participant in the file\n",
    "    Create a dataframe for each participant and concat all frames at the end.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_path = \"/home/kti01/Documents/My Files/Projects/Overlap/data/Data Upload/Ham10k_test_masked\"\n",
    "\n",
    "    # Create a dictionary with groups as keys and image masks as values.\n",
    "    # Image masks are sorted in ascending order, same order as the participants process them.\n",
    "    masks_dict = {}\n",
    "    for i in range(1, 15):\n",
    "        masks = sorted(os.listdir(os.path.join(mask_path, str(i))))\n",
    "        masks = [mask.split('.')[0] for mask in masks]\n",
    "        masks.insert(12, masks.pop(14))\n",
    "        masks_dict[str(i)] = masks\n",
    "    \n",
    "    files = os.listdir(data_path)\n",
    "    participant_dfs = []\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        if not file.endswith('csv'):\n",
    "            continue\n",
    "\n",
    "        data = pd.read_csv(os.path.join(data_path, file)).dropna(subset=dropna_subset_col)\n",
    "        # Get the group number from the file name\n",
    "        group = file.split('.')[0].split('_')[-1][5:]\n",
    "        \n",
    "        for participant in data[participant_id_column]:\n",
    "            df = data[data[participant_id_column] == participant].iloc[:, 6:81].transpose().copy()\n",
    "\n",
    "            participant_dict = {\n",
    "                'participant': [participant] * 15,\n",
    "                'group': [group] * 15,\n",
    "                'mask': masks_dict[group],\n",
    "                'prediction': [],\n",
    "                'confidence': [],\n",
    "                'trust': [],\n",
    "                'issues': []\n",
    "            }\n",
    "            # Loop through each question group (5 questions) at a time\n",
    "            for i in range(0, len(df), 5):\n",
    "                participant_dict['prediction'].append(df.iloc[i].item())\n",
    "                participant_dict['confidence'].append(df.iloc[i+1].item())\n",
    "                participant_dict['trust'].append(df.iloc[i+2].item())\n",
    "\n",
    "                issues = str(df.iloc[i+3].item())\n",
    "                if not pd.isna(df.iloc[i+4].item()):\n",
    "                    issues += ', '+df.iloc[i+4].item()\n",
    "\n",
    "                participant_dict['issues'].append(issues)\n",
    "                \n",
    "            participant_df = pd.DataFrame(participant_dict)\n",
    "            participant_dfs.append(participant_df)\n",
    "            \n",
    "    # Create metadata dataframe from all participants' frames.\n",
    "    metadata = pd.concat(participant_dfs)\n",
    "    \n",
    "    \n",
    "    # Read testset metadata and results files to map masks to image_ids and also \n",
    "    #  get the ground truth and AI predictions.\n",
    "    metadata_testset = pd.read_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/metadata_testset.csv\")\n",
    "    result_test = pd.read_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/result_test.csv\").rename({'prediction': 'AI_prediction'}, axis=1)\n",
    "\n",
    "    # Map masks to image_ids by creating a dict of mappings\n",
    "    mask_to_image_id = dict(zip(metadata_testset['mask'], metadata_testset['image_id']))\n",
    "    metadata['image_id'] = metadata.apply(lambda row: mask_to_image_id[int(row['mask'])] if row['mask'] != '9898' else row['mask'], axis=1)\n",
    "\n",
    "    # Add ground truth and AI prediction columns to metadata by merging with the result_test dataframe \n",
    "    metadata = pd.merge(metadata, result_test[['image_id', 'benign_malignant', 'AI_prediction']], \n",
    "                        on='image_id', how='left')\n",
    "    \n",
    "    \n",
    "    metadata['prediction'] = metadata['prediction'].apply(lambda x: 1 if x in ['Melanoma', 'Melanom'] else \n",
    "                                                  (0.5 if x in ['Nevus (excise)', 'NÃ¤vus (exzidieren)'] else 0))\n",
    "\n",
    "    metadata['confidence'] = metadata['confidence'].apply(lambda x: 10 if 'absolut sicher' in str(x) else\n",
    "                                                     (1 if 'gar nicht sicher' in str(x) else x))\n",
    "\n",
    "    metadata['confidence'] = metadata['confidence'].apply(lambda x: 10 if 'Completely' in str(x) else\n",
    "                                                     (1 if 'Not at all' in str(x) else x))\n",
    "\n",
    "    metadata['trust'] = metadata['trust'].apply(lambda x: 10 if 'vollkommen' in str(x) else\n",
    "                                                     (1 if 'gar nicht' in str(x) else x))\n",
    "\n",
    "    metadata['trust'] = metadata['trust'].apply(lambda x: 10 if 'Completely' in str(x) else\n",
    "                                                     (1 if 'Not at all' in str(x) else x))\n",
    "    \n",
    "    metadata['trust'] = metadata['trust'].apply(lambda x: 10 if 'absolut sicher' in str(x) else\n",
    "                                                     (1 if 'gar nicht sicher' in str(x) else x))\n",
    "    \n",
    "    # Set datatypes\n",
    "    metadata['confidence'] = metadata['confidence'].astype(int)\n",
    "    metadata['trust'] = metadata['trust'].astype(int)\n",
    "    \n",
    "    # Map participant Emails to Codes defined in participants.csv\n",
    "    participants_df = pd.read_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/participants.csv\")\n",
    "    participants_df['E-Mail'] = participants_df['E-Mail'].apply(lambda x: x.strip() if pd.notna(x) else x)\n",
    "    participants_code_dict = dict(zip(participants_df['E-Mail'], participants_df['Code']))\n",
    "\n",
    "    metadata['participant'] = metadata.apply(lambda row: participants_code_dict[row['participant']] \n",
    "                                             if row['participant'] in participants_code_dict and \n",
    "                                             pd.notna(participants_code_dict[row['participant']])\n",
    "                                             else row['participant'], axis=1)\n",
    "    metadata['language'] = metadata['participant'].apply(lambda x: 'en' if x.startswith('e') else 'de')\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9aae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbdb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_path = \"/home/kti01/Documents/My Files/Projects/Overlap/data/phase2/groups\"\n",
    "\n",
    "metadata_phase2 = process_metadata(phase2_path, participant_id_column='email. Email address', dropna_subset_col='submitdate. Date submitted')\n",
    "metadata_phase2.to_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/phase2/metadata_phase2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f019e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b2826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase3_path = \"/home/kti01/Documents/My Files/Projects/Overlap/data/phase3/groups\"\n",
    "\n",
    "metadata_phase3 = process_metadata(phase3_path, participant_id_column='email', dropna_subset_col='submitdate')\n",
    "metadata_phase3.to_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/phase3/metadata_phase3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc8307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c537e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab4874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccfddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754ac06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fece9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32429407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b672bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ef4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c0fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {}\n",
    "for participant in metadata_phase3.participant.unique():\n",
    "    p2 = metadata_phase2[metadata_phase2.participant==participant].dropna()\n",
    "    p3 = metadata_phase3[metadata_phase3.participant==participant].dropna()\n",
    "    # Acc\n",
    "    p2_acc_floor = metrics.balanced_accuracy_score(p2.benign_malignant, np.floor(p2.prediction)).round(3)\n",
    "    p2_acc_ceil = metrics.balanced_accuracy_score(p2.benign_malignant, np.ceil(p2.prediction)).round(3)\n",
    "    p2_AI_acc = metrics.balanced_accuracy_score(p2.benign_malignant, p2.AI_prediction).round(3)\n",
    "    # Sen\n",
    "    p2_sen_floor = metrics.recall_score(p2.benign_malignant, np.floor(p2.prediction)).round(3)\n",
    "    p2_sen_ceil = metrics.recall_score(p2.benign_malignant, np.ceil(p2.prediction)).round(3)\n",
    "    # Spec\n",
    "    p2_spec_floor = metrics.recall_score(p2.benign_malignant, np.floor(p2.prediction), pos_label=0).round(3)\n",
    "    p2_spec_ceil = metrics.recall_score(p2.benign_malignant, np.ceil(p2.prediction), pos_label=0).round(3)\n",
    "    \n",
    "    # Acc\n",
    "    p3_acc_floor = metrics.balanced_accuracy_score(p3.benign_malignant, np.floor(p3.prediction)).round(3)\n",
    "    p3_acc_ceil = metrics.balanced_accuracy_score(p3.benign_malignant, np.ceil(p3.prediction)).round(3)\n",
    "    p3_AI_acc = metrics.balanced_accuracy_score(p3.benign_malignant, p3.AI_prediction).round(3)\n",
    "    # Sen\n",
    "    p3_sen_floor = metrics.recall_score(p3.benign_malignant, np.floor(p3.prediction)).round(3)\n",
    "    p3_sen_ceil = metrics.recall_score(p3.benign_malignant, np.ceil(p3.prediction), pos_label=0).round(3)\n",
    "    # Spec\n",
    "    p3_spec_floor = metrics.recall_score(p3.benign_malignant, np.floor(p3.prediction), pos_label=0).round(3)\n",
    "    p3_spec_ceil = metrics.recall_score(p3.benign_malignant, np.ceil(p3.prediction), pos_label=0).round(3)\n",
    "    \n",
    "    group = p3.group.iloc[0]\n",
    "    \n",
    "    accuracy_dict[participant] = [group, p3_AI_acc,\n",
    "                                  p2_acc_floor, p3_acc_floor, \n",
    "                                  p2_sen_floor, p3_sen_floor,\n",
    "                                  p2_spec_floor, p3_spec_floor,\n",
    "                                  p2_acc_ceil, p3_acc_ceil, \n",
    "                                  p2_sen_ceil, p3_sen_ceil,\n",
    "                                  p2_spec_ceil, p3_spec_ceil,\n",
    "                                  ]\n",
    "df = pd.DataFrame.from_dict(accuracy_dict, orient='index').reset_index()\n",
    "df.columns = ['Participant', 'Group', 'AI Accuracy',\n",
    "              'Accuracy floor (Phase 2)', 'Accuracy floor (Phase 3)', \n",
    "              'Sensitivity floor (Phase 2)', 'Sensitivity floor (Phase 3)',\n",
    "              'Specificity floor (Phase 2)', 'Specificity floor (Phase 3)',\n",
    "              \n",
    "              'Accuracy ceil (Phase 2)', 'Accuracy ceil (Phase 3)', \n",
    "              'Sensitivity ceil (Phase 2)', 'Sensitivity ceil (Phase 3)',\n",
    "              'Specificity ceil (Phase 2)', 'Specificity ceil (Phase 3)',]\n",
    "df.to_csv('doctor_accuracy_phase2+3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6c0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e44c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d41f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_phase1 = pd.read_csv(\"/home/kti01/Documents/My Files/Projects/Overlap/data/phase1/metadata_phase1.csv\")\n",
    "\n",
    "accuracy_dict = {}\n",
    "for participant in metadata_phase1.participant.unique():\n",
    "    p1 = metadata_phase1[metadata_phase1.participant==participant].dropna()\n",
    "    # Acc\n",
    "    p1_acc_floor = metrics.balanced_accuracy_score(p1.benign_malignant, np.floor(p1.prediction)).round(3)\n",
    "    p1_acc_ceil = metrics.balanced_accuracy_score(p1.benign_malignant, np.ceil(p1.prediction)).round(3)\n",
    "    #p1_AI_acc = metrics.balanced_accuracy_score(p2.benign_malignant, p2.AI_prediction).round(3)\n",
    "    # Sen\n",
    "    p1_sen_floor = metrics.recall_score(p1.benign_malignant, np.floor(p1.prediction)).round(3)\n",
    "    p1_sen_ceil = metrics.recall_score(p1.benign_malignant, np.ceil(p1.prediction)).round(3)\n",
    "    # Spec\n",
    "    p1_spec_floor = metrics.recall_score(p1.benign_malignant, np.floor(p1.prediction), pos_label=0).round(3)\n",
    "    p1_spec_ceil = metrics.recall_score(p1.benign_malignant, np.ceil(p1.prediction), pos_label=0).round(3)\n",
    "    \n",
    "    group = p1.group.iloc[0]\n",
    "    \n",
    "    accuracy_dict[participant] = [group,\n",
    "                                  p1_acc_floor,\n",
    "                                  p1_sen_floor,\n",
    "                                  p1_spec_floor,\n",
    "                                  p1_acc_ceil,\n",
    "                                  p1_sen_ceil,\n",
    "                                  p1_spec_ceil\n",
    "                                  ]\n",
    "df = pd.DataFrame.from_dict(accuracy_dict, orient='index').reset_index()\n",
    "df.columns = ['Participant', 'Group', \n",
    "              'Accuracy floor (Phase 1)',  \n",
    "              'Sensitivity floor (Phase 1)',\n",
    "              'Specificity floor (Phase 1)',\n",
    "              \n",
    "              'Accuracy ceil (Phase 1)', \n",
    "              'Sensitivity ceil (Phase 1)', \n",
    "              'Specificity ceil (Phase 1)']\n",
    "df.to_csv('doctor_accuracy_phase1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
