{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b14a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kti01/miniconda3/envs/artifact_detection/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import json \n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "from matplotlib.path import Path\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import draw\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.draw import polygon\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "image_size = 224\n",
    "\n",
    "\n",
    "def overlap(a, b, method='dice'):\n",
    "    a = a.astype(int).flatten()\n",
    "    b = b.astype(int).flatten()\n",
    "    tn, fp, fn, tp = confusion_matrix(a, b, labels=[0, 1]).ravel()\n",
    "    if method == 'dice':\n",
    "        return 2*tp / (2*tp + fp + fn)\n",
    "    elif method == 'jaccard':\n",
    "        return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "def polygon2mask(polygon):\n",
    "    \"\"\"\n",
    "    Create an image mask from polygon coordinates\n",
    "    \"\"\"\n",
    "    vertex_row_coords, vertex_col_coords, shape = polygon[:, 1], polygon[:, 0], (450, 600)\n",
    "    \n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = np.zeros(shape, dtype=float)\n",
    "    mask[fill_row_coords, fill_col_coords] = 1.\n",
    "    mask = transform.resize(mask, (image_size, image_size))\n",
    "    return mask.astype(np.int16)\n",
    "\n",
    "\n",
    "def process_annotations(y_annotations):\n",
    "    masks = [polygon2mask(ann) for ann in y_annotations]\n",
    "    mask = np.bitwise_or.reduce(masks)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def plot(polygons, image_id, feature, gt):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "    for i, polygon in enumerate(polygons):\n",
    "        polygons[i] = process_annotations(polygon)\n",
    "\n",
    "    img = io.imread(\"/home/kti01/Documents/My Files/Projects/Overlap/characteristics_classifier/data/HAM10000/HAM10000/\"+image_id+'.jpg')\n",
    "    transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.Resize((image_size, image_size)),\n",
    "                                    transforms.ToTensor()])\n",
    "    image = transform(img)\n",
    "\n",
    "    axs[0].imshow(torch.permute(image, (1, 2, 0)), alpha=1)\n",
    "    axs[0].imshow(polygons[0][0], alpha=0.3)\n",
    "    axs[1].imshow(torch.permute(image, (1, 2, 0)), alpha=1)\n",
    "    axs[1].imshow(polygons[1][0], alpha=0.3)\n",
    "    axs[2].imshow(torch.permute(image, (1, 2, 0)), alpha=1)\n",
    "    axs[2].imshow(cv2.bitwise_and(polygons[0][0].numpy(), polygons[1][0].numpy()), alpha=0.3)\n",
    "                      \n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    axs[2].set_xticks([])\n",
    "    axs[2].set_yticks([])\n",
    "    axs[0].title.set_text('Annotator 1')\n",
    "    axs[1].title.set_text('Annotator '+gt)\n",
    "    axs[2].title.set_text('Combined')\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(feature, fontsize=\"x-large\")\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join('combine_annotations/intersection', gt, str(image_id)+'_'+feature))\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "char_class_labels = ['TRBL', 'ESA', 'BDG', 'GP', 'PV', 'PRL', 'WLSA', 'PLR', 'PES', 'PIF', 'OPC', 'SPC', 'MVP', 'PRLC', 'PLF', 'PDES', 'APC', 'MS']\n",
    "#char_class_labels = ['image_id', 'TRBL', 'ESA', 'BDG', 'GP', 'PV', 'PRL', 'WLSA', 'PLR', 'PES', 'PIF', 'OPC', 'SPC', 'MVP', 'PRLC', 'PLF', 'PDES', 'APC', 'MS']\n",
    "mel_class_labels = ['TRBL', 'ESA', 'BDG', 'GP', 'PV', 'PRL', 'WLSA', 'PES', 'PLR']\n",
    "nv_class_labels = ['OPC', 'SPC', 'MVP', 'PRLC', 'PLF', 'PDES', 'APC', 'MS']\n",
    "mel_ann_labels = [label+'_annotation' for label in mel_class_labels]\n",
    "nv_ann_labels = [label+'_annotation' for label in nv_class_labels]\n",
    "char_ann_labels = [label+'_annotation' for label in char_class_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07536aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bb634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cfdcb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:53: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 8s, sys: 32.4 s, total: 6min 40s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "For each image with more than 1 annotator, intersect the annotations.\n",
    "After intersecting, compare each individual polygon with the intersected annotation.\n",
    "For each individual polygon, calculate the percentage of information lost (defined by percent of pixels lost).\n",
    "If this 'percentage pixel lost' value is greater than 0.8, \n",
    " add the individual polygon to the final intersected annotation.\n",
    "\"\"\"\n",
    "\n",
    "image_dir = \"/home/kti01/Documents/My Files/Data/HAM10000/HAM10000/\"\n",
    "metadata = pd.read_pickle(\"/home/kti01/Documents/My Files/Projects/Overlap/data/ground_truth/metadata_gt_consolidated.pkl\")\n",
    "annotations = {}\n",
    "\n",
    "# Loop through each image and each feature\n",
    "for image_id in metadata['image_id'].unique():\n",
    "    \n",
    "    # Add the image_id to the dict for the first time\n",
    "    annotations[image_id] = {}# {k: -1 for k in char_class_labels}\n",
    "    \n",
    "    df = metadata[metadata['image_id'] == image_id]\n",
    "    \n",
    "    for feature in char_class_labels:\n",
    "\n",
    "        masks = []\n",
    "        polygons = []\n",
    "\n",
    "        for annotation in df[feature+'_annotation'].values:\n",
    "            if annotation != -1:\n",
    "                # Store the masks for each individual annotator in masks list and store each individual\n",
    "                #  polygon in the polygons list\n",
    "                polygons.extend(annotation)\n",
    "                masks.append(process_annotations(annotation))\n",
    "\n",
    "        # If no masks have been added to the list (the feature hasn't been chosen by any annotator),\n",
    "        #  then skip the current feature.\n",
    "        if len(masks) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get the candidate mask by intersecting the individual masks using bitwise_and.reduce().\n",
    "        # If masks list only has 1 mask, bitwise_and.reduce() will simply remove the outer list,\n",
    "        #  producing a 2d mask. It is equivalent to masks[0]\n",
    "        candidate_mask = np.bitwise_and.reduce(np.stack(masks))\n",
    "        final_mask = candidate_mask.copy()\n",
    "        \n",
    "        # If image has been annotated by more than 1 annotator, they need to be combined.\n",
    "        if len(masks) > 1:\n",
    "            # Loop through each individual polygon\n",
    "            for i, polygon in enumerate(polygons):\n",
    "                # Get the mask for each polygon\n",
    "                mask = polygon2mask(polygon)\n",
    "\n",
    "                # Compare the mask with the candidate mask and calculate the percentage pixel lost value\n",
    "                compare = np.bitwise_and(mask, candidate_mask)\n",
    "                lost = (mask.sum() - compare.sum()) / mask.sum()  \n",
    "\n",
    "                if lost >= 0.8:\n",
    "                    final_mask = np.bitwise_or(final_mask, mask)\n",
    "                    \n",
    "        # Finally, add the final combined mask the the annotations dict.\n",
    "        annotations[image_id][feature] = final_mask.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090cad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotations for each image as json files\n",
    "for k, v in annotations.items():\n",
    "    file = json.dumps(v, separators=(',', ':'))\n",
    "    with open('/home/kti01/Documents/My Files/Projects/Overlap/data/ground_truth/annotations_gt/'+k+'.json', 'w') as f:\n",
    "        json.dump(file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb4f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7f9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246eca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6057fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c3ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
